{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gKIHsEunHrMV"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1YgKalQHv-O",
        "outputId": "20e69853-6065-4cda-a2fe-25d8492a8d78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'subsample': [0.7, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize the GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=XGBClassifier(), param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Cross-Validation Score:\", best_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJSyozz4H0HC",
        "outputId": "78e2f707-c5d2-46ca-ab97-c0f33e0755e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n",
            "Best Cross-Validation Score: 0.9500000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define the hyperparameter space\n",
        "param_distributions = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'subsample': [0.7, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=XGBClassifier(), param_distributions=param_distributions, n_iter=10, cv=3, scoring='accuracy', random_state=42)\n",
        "\n",
        "# Perform the random search\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and score\n",
        "best_params_random = random_search.best_params_\n",
        "best_score_random = random_search.best_score_\n",
        "\n",
        "print(\"Best Parameters (Random Search):\", best_params_random)\n",
        "print(\"Best Cross-Validation Score (Random Search):\", best_score_random)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOSgZSXmH3-3",
        "outputId": "3b4df03c-8c5c-4d38-e103-b9332ce0b126"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters (Random Search): {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 0.2}\n",
            "Best Cross-Validation Score (Random Search): 0.9583333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbvSO31GIGmD",
        "outputId": "b9b17c1b-b736-4942-d6b1-59d18b4f1eda"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.34)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
        "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 0.3)\n",
        "    }\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    return accuracy\n",
        "\n",
        "# Perform the optimization\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Get the best trial results\n",
        "best_trial = study.best_trial\n",
        "print(\"Best Trial Parameters:\", best_trial.params)\n",
        "print(\"Best Accuracy:\", best_trial.value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhjiq-J0IDwF",
        "outputId": "c4b5a61c-4808-4e85-c173-797b8467906d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-16 04:39:13,972] A new study created in memory with name: no-name-be4a0209-d350-47d8-ae74-6eec5e219ba0\n",
            "[I 2024-09-16 04:39:14,028] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 168, 'learning_rate': 0.11791040938037373, 'max_depth': 6, 'subsample': 0.860428103481157, 'gamma': 0.2836070044594087}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:14,080] Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 167, 'learning_rate': 0.14832308544251288, 'max_depth': 3, 'subsample': 0.7282296345476242, 'gamma': 0.27305159361958475}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:14,131] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 119, 'learning_rate': 0.03760380490121611, 'max_depth': 4, 'subsample': 0.8545612320915632, 'gamma': 0.2848371452735529}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:14,426] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 165, 'learning_rate': 0.0911033118896294, 'max_depth': 6, 'subsample': 0.9599519495241395, 'gamma': 0.03310539625470856}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:14,700] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 127, 'learning_rate': 0.04665625502667924, 'max_depth': 3, 'subsample': 0.7790835587182852, 'gamma': 0.24402708360355013}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:14,833] Trial 5 finished with value: 1.0 and parameters: {'n_estimators': 58, 'learning_rate': 0.19906917964140802, 'max_depth': 5, 'subsample': 0.9860029520178639, 'gamma': 0.2903458473668679}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:15,298] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 64, 'learning_rate': 0.15066978544257426, 'max_depth': 6, 'subsample': 0.755928534982206, 'gamma': 0.08285421308019437}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:15,744] Trial 7 finished with value: 1.0 and parameters: {'n_estimators': 118, 'learning_rate': 0.09758090230756628, 'max_depth': 3, 'subsample': 0.7369401116920279, 'gamma': 0.11229390629190233}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:15,893] Trial 8 finished with value: 1.0 and parameters: {'n_estimators': 71, 'learning_rate': 0.19659501617248712, 'max_depth': 6, 'subsample': 0.8995246939919251, 'gamma': 0.2079600586023661}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:16,105] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 94, 'learning_rate': 0.13401480496660448, 'max_depth': 4, 'subsample': 0.9162197922335591, 'gamma': 0.11759643784720047}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:16,580] Trial 10 finished with value: 1.0 and parameters: {'n_estimators': 198, 'learning_rate': 0.06887807031791252, 'max_depth': 5, 'subsample': 0.823803448051012, 'gamma': 0.18308816241785958}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:17,764] Trial 11 finished with value: 1.0 and parameters: {'n_estimators': 167, 'learning_rate': 0.1444530007111807, 'max_depth': 4, 'subsample': 0.7053641066651373, 'gamma': 0.23649184347908164}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:18,125] Trial 12 finished with value: 1.0 and parameters: {'n_estimators': 163, 'learning_rate': 0.12530895618071694, 'max_depth': 5, 'subsample': 0.8147719734765415, 'gamma': 0.26021575806012737}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:18,615] Trial 13 finished with value: 1.0 and parameters: {'n_estimators': 196, 'learning_rate': 0.1679620785966029, 'max_depth': 3, 'subsample': 0.8723605137502176, 'gamma': 0.19433799188541162}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:18,962] Trial 14 finished with value: 1.0 and parameters: {'n_estimators': 145, 'learning_rate': 0.01117082005293872, 'max_depth': 5, 'subsample': 0.7994111384213894, 'gamma': 0.2993374445909895}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:19,264] Trial 15 finished with value: 1.0 and parameters: {'n_estimators': 184, 'learning_rate': 0.1131342301651846, 'max_depth': 4, 'subsample': 0.7020435185848839, 'gamma': 0.16064904237913769}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:19,714] Trial 16 finished with value: 1.0 and parameters: {'n_estimators': 140, 'learning_rate': 0.16829788610071614, 'max_depth': 6, 'subsample': 0.9219986065731877, 'gamma': 0.2180803812440001}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:20,404] Trial 17 finished with value: 1.0 and parameters: {'n_estimators': 148, 'learning_rate': 0.08359901750375673, 'max_depth': 3, 'subsample': 0.8740756387551821, 'gamma': 0.263168395612027}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:20,669] Trial 18 finished with value: 1.0 and parameters: {'n_estimators': 177, 'learning_rate': 0.1705154691286871, 'max_depth': 5, 'subsample': 0.8342996686890909, 'gamma': 0.15903311524069907}. Best is trial 0 with value: 1.0.\n",
            "[I 2024-09-16 04:39:20,889] Trial 19 finished with value: 1.0 and parameters: {'n_estimators': 103, 'learning_rate': 0.11579079862377738, 'max_depth': 4, 'subsample': 0.7588424209836753, 'gamma': 0.04154507128856977}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial Parameters: {'n_estimators': 168, 'learning_rate': 0.11791040938037373, 'max_depth': 6, 'subsample': 0.860428103481157, 'gamma': 0.2836070044594087}\n",
            "Best Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}